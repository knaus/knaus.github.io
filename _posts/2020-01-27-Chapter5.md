# Multiple regression with Bayesian methods

A multiple regression model helps us understand how much better we get
at predicting the outcome from knowing each predictor variable. To
better understand how multiple regression works in the Bayesian world,
I’m going to step through the example described in [Statistical
Rethinking](https://github.com/rmcelreath/statrethinking_winter2019) aka
the most amazing stat book ever.

The Waffle Divorce data set from Chapter 5 has the divorce rate (D),
marriage rate (M) and median age at marriage (A) for each of the 50
states. The task is to predict the divorce rate D. How much does it help
me to know the marriage rate or the median age at marriage?

Another way to think of this question is in terms of causality. What
causes D? Is it M? Is it A? Does A cause M, and D indirectly through M?
This sort of causal relationships are summarized by graphs (DAGs) as the
one below. We’re going to use a multiple regression model to start
pinning down which variables are useful when we want to predict D.

<img src="/images/2020-01-27-Chapter5/dags-1.png" style="display: block; margin: auto;" />

Here’s how the data we’re working with looks like,including the
variables we care about: divorce rate (D), marriage rate (M) and median
age at marriage (A).

``` r
data(WaffleDivorce)
d <- WaffleDivorce
head(d,5)
```

    ##     Location Loc Population MedianAgeMarriage Marriage Marriage.SE Divorce
    ## 1    Alabama  AL       4.78              25.3     20.2        1.27    12.7
    ## 2     Alaska  AK       0.71              25.2     26.0        2.93    12.5
    ## 3    Arizona  AZ       6.33              25.8     20.3        0.98    10.8
    ## 4   Arkansas  AR       2.92              24.3     26.4        1.70    13.5
    ## 5 California  CA      37.25              26.8     19.1        0.39     8.0
    ##   Divorce.SE WaffleHouses South Slaves1860 Population1860 PropSlaves1860
    ## 1       0.79          128     1     435080         964201           0.45
    ## 2       2.05            0     0          0              0           0.00
    ## 3       0.74           18     0          0              0           0.00
    ## 4       1.22           41     1     111115         435450           0.26
    ## 5       0.24            0     0          0         379994           0.00

An initial plot shows a possible association of divorce rate (D) with
marriage rate (M) or median age at marriage (A) separately.

<img src="/images/2020-01-27-Chapter5/plots1-1.png" style="display: block; margin: auto;" /><img src="/images/2020-01-27-Chapter5/plots1-2.png" style="display: block; margin: auto;" />

At the beginning of the analysis we standardize the variables so they’ll
have mean 0 and SD 1. Let’s check that the divorce rate is standardized
and take a look at how this variable is distributed.

``` r
d$A <- scale( d$MedianAgeMarriage )
d$M <- scale( d$Marriage)
d$D <- scale( d$Divorce )
mean(d$D)
```

    ## [1] -3.169351e-16

``` r
sd(d$D)
```

    ## [1] 1

``` r
dens(d$D)
```

<img src="/images/2020-01-27-Chapter5/data_prep-1.png" style="display: block; margin: auto;" />

The linear model below describes what information we have to predict the
mean of the divorce rate D for each observation. The parameters betaM
and betaM describe the influence of knowing the predictor variables M
and A on what we predict for D. The letter i (subscript i in stat
textbooks) means that the model here applies for every row of data
(observation) we have. For every M and A observations we have (let’s say
20 and 31), we can draw parameters alpha, betaM and betaA from their
joint distribution and calculate a value for the mean of the divorce
rate. With the mean of the divorce rate and the sigma at hand, we have a
full description of the likely values for divorce rate (the distribution
of the divorce rate being normal), from which we can draw a value for
Di. This is the prediction side, once we know the joint probabilities
for all the parameters. When we fit the model, we figure out (well,
automatically aka the computer finds the solution for us) which
parameter distribution gives us values of Di which are closest to the
ones we see in the data with rows of divorce rate, marriage rate, median
age at marriage values.

Di \~ Normal (mui, sigma) mui = alpha + betaM \* Mi + betaA \* Ai alpha
\~ Normal(0, 0.2) \[prior for alpha\] betaM \~ Normal(0, 0.5) \[prior
for betaM\] betaA \~ Normal(0, 0.5) \[prior for betaA\] sigma \~
Exponential(1)

``` r
m5.1 <- quap(
              alist(
                    D ~ dnorm(mu, sigma) ,
                              mu <- a + betaM*M + betaA * A,
                              a ~ dnorm(0 , 0.2) ,
                              betaM ~ dnorm(0, 0.5),
                              betaA ~ dnorm(0, 0.5),
                              sigma ~ dexp(1)), data = d)
precis(m5.1)
```

    ##                mean         sd       5.5%      94.5%
    ## a     -6.569756e-07 0.09707591 -0.1551467  0.1551454
    ## betaM -6.538176e-02 0.15077285 -0.3063459  0.1755824
    ## betaA -6.135138e-01 0.15098339 -0.8548144 -0.3722131
    ## sigma  7.851168e-01 0.07784309  0.6607085  0.9095251

Because betaM mean is around 0, knowing the marriage rate doesn’t
improve the estimation of divorce rate. However, knowing median age at
marriage (A) is most helpful in predicting divorce rate. This model can
be the start of an analysis whether there’s a causal relationship
between A and D.

OK, but how did we choose these prior distributions? We chose a to be
centered at 0 because we’re working with standardized data with 0 mean.
For each of the betaM and betaA parameters, we’re going to look at the
simpler case of single regression and see what kind of divorce rate they
allow. Let’s take betaA.

``` r
m5.2 <- quap(
            alist(
                  D ~ dnorm(mu, sigma),
                            mu <- a + betaA * A,
                            a ~ dnorm(0, 0.2),
                            betaA ~ dnorm(0, 0.1),
                            sigma ~ dexp(1)) , data=d )
m5.3 <- quap(
            alist(
                  D ~ dnorm(mu, sigma),
                            mu <- a + betaA * A,
                            a ~ dnorm(0, 0.2),
                            betaA ~ dnorm(0, 0.5),
                            sigma ~ dexp(1)), data = d )
m5.4 <- quap(
            alist(
                  D ~ dnorm(mu, sigma),
                            mu <- a + betaA * A,
                            a ~ dnorm(0, 0.2),
                            betaA ~ dnorm(0, 1),
                            sigma ~ dexp(1)) , data=d)

par(mfcol=c(2,3))
prior <- extract.prior( m5.2 )
mu5.2 <- link( m5.2 , post=prior , data=list( A=c(-2,2) ) )
curve( dnorm( x , 0 , 0.1) , from =-1, to=1)
title(main = "betaA ~ dnorm(0,0.1)")
plot( NULL , xlim=c(-2,2) , ylim=c(-2,2), xlab="Median age at marriage (std)", ylab="Divorce rate (std)" )
for ( i in 1:50 ) lines( c(-2,2) , mu5.2[i,] , col=col.alpha("black",0.4) )

prior <- extract.prior( m5.3 )
mu5.3 <- link( m5.3 , post=prior ,  data=list( A=c(-2,2) ) )
curve( dnorm( x , 0 , 0.5) , from =-1, to=1)
title(main="betaA ~ dnorm(0,0.5)")
plot( NULL , xlim=c(-2,2) , ylim=c(-2,2) , xlab="Median age at marriage (std)", ylab="Divorce rate (std)")
for ( i in 1:50 ) lines( c(-2,2) , mu5.3[i,] , col=col.alpha("black",0.4) )

prior <- extract.prior( m5.4 )
mu5.4 <- link( m5.4 , post=prior , data=list( A=c(-2,2) ) )
curve( dnorm( x , 0 , 1) , from =-1, to=1)
title(main="betaA ~ dnorm(0,1)")
plot( NULL , xlim=c(-2,2) , ylim=c(-2,2), xlab="Median age at marriage (std)", ylab="Divorce rate (std)" )
for ( i in 1:50 ) lines( c(-2,2) , mu5.4[i,] , col=col.alpha("black",0.4) )
```

<img src="/images/2020-01-27-Chapter5/single_model-1.png" style="display: block; margin: auto;" />
As you can see above, as the distribution for betaA becomes broader,
from a normal dist with SD=0.1 to one with a SD=1, the relationship
between Median age at marriage(A) and Divorce rate(D) can get very
steep, past what’s reasonable to expect.
