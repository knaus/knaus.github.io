A linear regression model helps us understand how much extra
information, apart from what we can already know, can be gained by
knowing an additional predictor variable. To better understand how
multiple regression works in the Bayesian world, I’m going to step
through the example described in [Statistical
Rethinking](https://github.com/rmcelreath/statrethinking_winter2019) aka
the most amazing stat book ever.

The Waffle Divorce data set from Chapter 5 has the divorce rate (D),
marriage rate (M) and median age at marriage (A) for each of the 50
states. I’d like to know how much does it help knowing the marriage rate
or the median age at marriage if I’d like to predict divorce rate.

Here’s a glimpse at the data we’re working with and an initial plot
showing a possible association of divorce rate (D) with marriage rate
(M) or median age at marriage (A) separately.

``` r
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce
head(d,5)
```

    ##     Location Loc Population MedianAgeMarriage Marriage Marriage.SE Divorce
    ## 1    Alabama  AL       4.78              25.3     20.2        1.27    12.7
    ## 2     Alaska  AK       0.71              25.2     26.0        2.93    12.5
    ## 3    Arizona  AZ       6.33              25.8     20.3        0.98    10.8
    ## 4   Arkansas  AR       2.92              24.3     26.4        1.70    13.5
    ## 5 California  CA      37.25              26.8     19.1        0.39     8.0
    ##   Divorce.SE WaffleHouses South Slaves1860 Population1860 PropSlaves1860
    ## 1       0.79          128     1     435080         964201           0.45
    ## 2       2.05            0     0          0              0           0.00
    ## 3       0.74           18     0          0              0           0.00
    ## 4       1.22           41     1     111115         435450           0.26
    ## 5       0.24            0     0          0         379994           0.00

``` r
plot(d$Divorce ~ d$Marriage , data=WaffleDivorce ,xlab="Marriage rate (per 1000 adults)", ylab="Divorce rate (per 1000 adults)",col=col.alpha(rangi2,0.4) )
```

![](2020-01-27-Chapter5_files/figure-markdown_github/intro-1.png)

``` r
plot(d$Divorce ~ d$MedianAgeMarriage,  data=WaffleDivorce ,xlab="Median age at marriage (years)", ylab="Divorce rate (per 1000 adults)", col=col.alpha(rangi2,0.4))
```

![](2020-01-27-Chapter5_files/figure-markdown_github/intro-2.png)

At the beginning of the analysis we standardize the variables. They’ll
have a mean 0 and SD 1. Let’s check that the divorce rate is
standardized. Let’s look at how this variable is distributed.

``` r
# standardize variables
d$A <- scale( d$MedianAgeMarriage )
d$M <- scale( d$Marriage)
d$D <- scale( d$Divorce )
mean(d$D)
```

    ## [1] -3.169351e-16

``` r
sd(d$D)
```

    ## [1] 1

``` r
dens(d$D)
```

![](2020-01-27-Chapter5_files/figure-markdown_github/data_prep-1.png)

The linear model below describes what information we have to predict the
mean of the divorce rate D for each observation. The parameters betaM
and betaM describe the influence of knowing the predictor variables M
and A on what we predict for D.

Di \~ Normal (mui, sigma) mui = alpha + betaM \* Mi + betaA \* Ai alpha
\~ Normal(0, 0.2) \[prior for alpha\] betaM \~ Normal(0, 0.5) \[prior
for betaM\] betaA \~ Normal(0, 0.5) \[prior for betaA\] sigma \~
Exponential

``` r
m5.1 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bA * A ,
a ~ dnorm( 0 , 0.2 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
```
